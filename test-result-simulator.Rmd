---
title: "|  A/B Test Result Simulator"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    css: styles.css
    vertical_layout: scroll
    logo: logo-sm.png
    favicon: favicon.png
    includes:
      in_header: header.html
      after_body: tracking.html
runtime: shiny
---

```{r setup}
library(tidyverse)
library(scales)

# Specify the base colors for A and B. These get used in various places
color_a <- "#00A2B1"
color_b <- "#9A258F"

# Set a seed for reproducibility
set.seed(112069)

```

Column {.sidebar data-width=400}
-------------------------------------

### Configure the Simulation

Enter the (_**unknowable in reality!**_) conversion rates for **A** and **B** below (if we _only_ ran **A** or _only_ ran **B** for _all_ traffic for all time and _all other contributing factors were held constant_):

```{r}
# Conversion Rate for A
div(style="text-align: center;",
    div(style="display:inline-block; padding-right: 5px; font-weight: bold; font-family: Nunito", "A:"),
    div(style="display:inline-block; font-family: Nunito;", numericInput("rate_a", label = NULL, value = 5.0, width = "100px")),
    div(style="display:inline-block; padding-left: 5px; font-weight: bold; font-family: Nunito", "%"))
```

```{r}
# Conversion Rate for B
div(style="text-align: center;",
    div(style="display:inline-block; padding-right: 5px; font-weight: bold; font-family: Nunito", "B:"),
    div(style="display:inline-block; font-family: Nunito", numericInput("rate_b", label = NULL, value = 5.5, width = "100px")),
    div(style="display:inline-block; padding-left: 5px; font-weight: bold; font-family: Nunito", "%"))
```

How many visit(or)s experienced **each variation** of the test?

```{r}
# Number of visitors
div(style="text-align: center;",
    div(style="display:inline-block",
        sliderInput("num_observations",
                    label = NULL,
                    min = 1000, max = 100000, value = 25000, step = 1000)))
```

_Click below to simulate a test (a new simulation will automatically run if any of the parameters above are updated)._

```{r}
div(style="text-align: center;",
    div(style="display:inline-block",
        actionButton("run_test", "Run a Simulation!")))

```


-----

### Annualize the Revenue Impact

_To experiment with estimating the revenue impact ("estimating the treatment effect"), we need some additional information:_

For how many days did the test run?

```{r}
# Test duration
div(style="text-align: center;",
    div(style="display:inline-block",
        numericInput("test_duration", 
                     label = NULL, value = 14,
                     width = "100px")))
```

What's the average order value (AOV) for the site?

```{r}
# Test duration
div(style="text-align: center;",
    div(style="display:inline-block",numericInput("aov", 
                                                  label = NULL, value = 100,
                                                  width = "100px")))
```


Row
-----------------------------

### Overview and Purpose

This simulator is designed to illustrate -- through calculations and simulation -- the difference between an _observed_ result in an A/B test and the _actual/true value_ _**(which is completely unknowable, but extremely useful to think about)**_.

Row {data-height=500}
-----------------------------

### Visualizing the Results

In the real world, we don't know the _actual_ values for **A** and **B**. We just know what we _observed_. If we did know the actual values, and we knew how many visitors we would have (which we've entered at left), then we could predict where the _observed_ values would fall. That's what the distributions are representing -- the magic of simulations in which we can see the normally unseeable.

```{r}

# Show the distributions
plotOutput("main_plot")

```


Row
-----------------------------

### Assessment #1: Detecting the EXISTENCE of an Effect

Does the observed difference in **A** and **B** indicate that the two variations are truly different? (This is question that sample size calculators generally focus on: _detecting an effect_ only).


Row {data-height=260}
-----------------------------

### Check for Statistical Significance {data-width=667}

```{r results_assess}
# Output the summary explanation. This is built up with all of the
# formatting in the summary_message output.
uiOutput("summary_message")

```

### Which Means We Have a... {data-width=333}

```{r results_viz, fig.height = 1}

plotOutput("result_type")

```


Row
-----------------------------

### Assessment #2: Estimating the SIZE of the Effect

Can you simply use the observed difference in **A** and **B** to estimate the annualized impact of the winning variation? You can...but that can be risky, as it will overstate or understate the "true" value, and it may do so by quite a bit (while also assuming all other factors remain constant, which is never the case).

Row {data-height=250} 
-----------------------------

### A Visual Comparison of the Lift %s {data-width=333}

```{r conversion_rate_plot}
# A bar chart showing the actual lift, and then the observed lift
# with the confidence interval.
plotOutput("conv_rate_lift")
```

### Annualizing Revenue Impact {data-width=667}

```{r annualization_assess}

uiOutput("annual_rev_message")

```


```{r base_calculations}
# Calculations used multiple times .These are all reactive because they get repurposed a bit.

# Convert the entered rates to percents
rate_a_percent <- reactive({
  input$rate_a/100
})

rate_b_percent <- reactive({
  input$rate_b/100
})

# Calculate the standard deviation for A and B. Handy reference:
# https://stattrek.com/probability-distributions/binomial.aspx
sd_a <- reactive({
  sqrt(input$num_observations * rate_a_percent() * (1 - rate_a_percent())) / input$num_observations
})

sd_b <- reactive({
  sqrt(input$num_observations * rate_b_percent() * (1 - rate_b_percent())) / input$num_observations 
})

# Simulate a test -- simulate values for both A and for B
a_observed <- reactive({
  # For to re-run when the button is clicked
  input$run_test
  # Actually do a simulation
  rbinom(input$num_observations, 1, rate_a_percent()) %>% sum()/input$num_observations
})

b_observed <- reactive({
  # For to re-run when the button is clicked
  input$run_test
  # Actually do a simulation
  b_observed <- rbinom(input$num_observations, 1, rate_b_percent()) %>% sum()/input$num_observations
})

# Calculate the 95% confidence interval for A and for B based on the observed values. 
# See: https://sigmazone.com/binomial-confidence-intervals/ and
# http://statpages.info/confint.html. 

xmin_a <- reactive({
  prop_test <- prop.test(a_observed() * input$num_observations, input$num_observations)
  prop_test$conf.int[[1]]
})

xmax_a <- reactive({
  prop_test <- prop.test(a_observed() * input$num_observations, input$num_observations)
  prop_test$conf.int[[2]]
})

xmin_b <- reactive({
  prop_test <- prop.test(b_observed() * input$num_observations, input$num_observations)
  prop_test$conf.int[[1]]
})

xmax_b <- reactive({
  prop_test <- prop.test(b_observed() * input$num_observations, input$num_observations)
  prop_test$conf.int[[2]]
})

# 2-sample test of proportions. We'll need this for the p-value and for
# the confidence interval
prop_test <- reactive({
  
  # Run a 2-sample test of proportions. This is checking the null hypothesis
  # that B is NOT GREATER THAN A (a one-tailed test) if B > A.
  # If the simulation is set up as an A/A test, we want to use a two-tailed
  # assessment. Otherwise, we'll use one-tailed.
  if(input$rate_a == input$rate_b){
    prop_test <- prop.test(x = c(b_observed() * input$num_observations, 
                                 a_observed() * input$num_observations), 
                           n = rep(input$num_observations,2),
                           alternative = "two.sided")
    
  } else {
    prop_test <- prop.test(x = c(b_observed() * input$num_observations, 
                                 a_observed() * input$num_observations), 
                           n = rep(input$num_observations,2),
                           alternative = "greater")
  }
  
  # Write out to the console just for debug reference
  cat("Conf. interval:", prop_test$conf.int, "\n")
  
  prop_test
})

# Get the p-value
p_val <- reactive({
  
  p_val <- prop_test()$p.value
  
})

# Calculate the 95% confidence interval for the 2-sample difference in proportions
# https://www.socscistatistics.com/confidenceinterval/default4.aspx.
# http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Confidence_Intervals/BS704_Confidence_Intervals5.html.
# https://www.dummies.com/education/math/statistics/how-to-estimate-the-difference-between-two-proportions/
# The actual results returned use prop.test *with* continuity correction, so don't quite
# match the formulas provided in the links above. And, the calculations are a little different
# if B > A (one-sided test) vs. if B = A (an A/A/ test -- two-sided)
min_lift_proportion <- reactive({

  # Get the confidence interval from prop.test. This will run as one-sided
  # or two-sided as appropriate.
  conf_int <- prop_test()$conf.int

  # Calculate the min value and return it
  min_lift_proportion <- conf_int[[1]]
  min_lift_proportion
})

max_lift_proportion <- reactive({

  # Get the confidence interval from prop.test. This will run as one-sided
  # or two-sided as appropriate.
  conf_int <- prop_test()$conf.int

  # Calculate the max value and return it
  max_lift_proportion <- 2 * (b_observed() - a_observed()) - conf_int[[1]]
  max_lift_proportion
})

```

```{r main_plot}
# Build the main plot

output$main_plot <- renderPlot({
  
  # In order to work with one-tailed and not allow squirrely results, we're going to
  # force the settings to be such that B >= A. So, build a plot that is just a message
  # that that is required and display that if B < A.
  if(input$rate_b < input$rate_a){
    gg <- ggplot(data = data.frame(x = 1, y = 1, 
                                   label = paste("Please set the value of B to",
                                                 "be greater than or equal to the value for A.")),
                 mapping = aes(x = x, y = y, label = label)) +
      geom_text(size = 10, fontface = "italic", family = "Nunito", colour = "#0060AF") +
      theme_light() +
      theme(line = element_blank(),
            text = element_blank(),
            panel.border = element_blank())
  } else {
    
    # We want to keep the limits of the x axis constant regardless of the #
    # of observations, so calculate those limits based on 1000 and 3 * the
    # standard deviation. This way, the user will see the distribution physically 
    # get narrower or tighter as they adjust the # of observations.
    min_x <- min(
      rate_a_percent() - (sqrt(1000 * rate_a_percent() * (1 - rate_a_percent())) / 1000) * 3,
      rate_b_percent() - (sqrt(1000 * rate_b_percent() * (1 - rate_b_percent())) / 1000) * 3
    )
    
    max_x <- max(
      rate_a_percent() + (sqrt(1000 * rate_a_percent() * (1 - rate_a_percent())) / 1000) * 3,
      rate_b_percent() + (sqrt(1000 * rate_b_percent() * (1 - rate_b_percent())) / 1000) * 3
    )
    
    # go ahead and figure the offset to get the Actual line labels to be offset appropriatesly
    label_offset <- (max_x - min_x)/80
    
    # For visual clarity, we want to scale the y-axis so that the "top peak" stays
    # pretty much constant with enough room above it to put the labels. So, we're
    # going to use the same density function that gets used to draw the distributions
    # in the plot. The peak will be the mean, so we'll look at both means and see which
    # is greater.
    max_y <- max(dnorm(x = rate_a_percent(), mean = rate_a_percent(), sd = sd_a()),
                 dnorm(x = rate_b_percent(), mean = rate_b_percent(), sd = sd_b()))
    
    #########
    # Simulate the tests
    #########
    
    # Get the simulated data from the reactive functions defined earlier
    a_observed <- a_observed()
    b_observed <- b_observed()
    xmin_a <- xmin_a()
    xmax_a <- xmax_a()
    xmin_b <- xmin_b()
    xmax_b <- xmax_b()
    
    # We want to display the values within the distribution, so calculate the top of the
    # curve using a_observed and then set a y that is 2/3 of that; so the same for B and set
    # it at 1/3. This will let the confidence interval lines not fall on top of each other.
    # Yeah. I'm kinda' proud of this little bit.
    a_observed_y <- dnorm(x = a_observed, mean = rate_a_percent(), sd = sd_a()) * 2/3
    b_observed_y <- dnorm(x = b_observed, mean = rate_b_percent(), sd = sd_b()) * 1/3
    
    # Create a data frame with the values
    observed_df <- data.frame(name = c("(Observed) A: ", "(Observed) B: "),
                              x = c(a_observed, b_observed),
                              xmin = c(xmin_a, xmin_b),          # Error bar min
                              xmax = c(xmax_a, xmax_b),          # Error bar max
                              y = c(a_observed_y, b_observed_y))
    
    ########
    # Create the main plot
    ########
    gg <- ggplot(data = data.frame(x = c(min_x, max_x)), aes(x)) +
      
      # Draw the two distributions
      stat_function(fun = dnorm, n = 300, geom = "area", 
                    args = list(mean = rate_a_percent(), sd = sd_a()),
                    fill = color_a, alpha = 0.1, color = "gray80",
                    linetype = "dotted", size = 1) +
      stat_function(fun = dnorm, n = 300, geom = "area",
                    args = list(mean = rate_b_percent(), sd = sd_b()),
                    fill = color_b, alpha = 0.1, color = "gray80",
                    linetype = "dotted", size = 1) +
      
      # Draw the two "actual" vertical lines and label them
      geom_vline(xintercept = rate_a_percent(), color = "gray30", linetype = "dashed", size = 1) +
      geom_text(aes(x = rate_a_percent() - label_offset, y = max_y * 1.05, 
                    label = paste0("(True!) A: ", format(rate_a_percent() * 100, nsmall = 2), "%")),
                hjust = 1, size = 5, family = "Nunito") +
      geom_vline(xintercept = rate_b_percent(), color = "gray30", linetype = "dashed", size = 1) +
      geom_text(aes(x = rate_b_percent() + label_offset, y = max_y * 1.05, 
                    label = paste0("(True!) B: ", format(rate_b_percent() * 100, nsmall = 2), "%")),
                hjust = 0, size = 5, family = "Nunito") +
      
      # Clean up the formatting
      scale_y_continuous(expand = c(0,0), limits = c(0, 1.1 * max_y), breaks = NULL) +
      theme_light() +
      theme(legend.position = "none",
            panel.border = element_blank(),
            panel.grid = element_blank(),
            plot.margin = margin(0,0,2.5,0, unit="cm"),   # Hacking around clipping in flexdashboard
            axis.title = element_blank(),
            axis.text = element_blank(),
            axis.line.x = element_line(color = "gray20"))
    
    # Add the simulated test results if any exist. If I try to do this with just a simple
    # 'if(input$run_test > 0)' and not an if/else, then the plot doesn't draw initially. I'm
    # not sure why.
    gg <- if(input$run_test == 0) {
      gg
    } else {
      gg +
        geom_errorbarh(mapping = aes(xmin = xmin, xmax = xmax, y = y), data = observed_df,
                       height = max_y/40, color = "gray30") +
        geom_point(mapping = aes(x=x, y=y, color = name, fill = name), data = observed_df, 
                   size = 4, shape = 23) +
        geom_label(mapping = aes(x=x, y=y + max_y/18, label = paste0(name, format(round(x * 100, 3), nsmall = 3), "%")),
                   size = 5, data = observed_df, family = "Nunito") +
        scale_fill_manual(values = c(color_a, color_b)) +
        scale_colour_manual(values = c(color_a, color_b))
      
    }}
  
  # Return the plot
  gg
  
})

```

```{r assess_results}

# All the functions for assessing the results

# Significance Message
output$summary_message <- renderUI({
  
  # Return nothing if no test has been run or if B < A
  if (input$run_test == 0 | input$rate_b < input$rate_a){
    return()
  } else {
    
    # Summarize the true and observed lifts
    summary_message <- div(class = "descriptions", 
                           "The true (absolute) lift from", em("A"), "to", em("B"), "is",
                           strong(percent((input$rate_b - input$rate_a)/100, accuracy = 0.01)), ", but, in the",
                           "real world, that's not a value we know. We just know what the",
                           strong("observed lift"), "from", em("A"), "to", em("B"), "was in our ",
                           "simulation:", strong(percent(b_observed() - a_observed(), accuracy = 0.01)), ".")
    
    # Get the p-value
    p_val <- p_val()
    
    # Check for significance and write out the HTML summarizing it
    if(p_val < 0.05){
      sig_message <- div(class = "descriptions", "The test", strong("IS significant"), " at a 95% confidence level (p-value =",
                         format(round(p_val, 4), nsmall = 4, scientific = FALSE), 
                         ", which is less than 0.05).", strong("We reject the null hypothesis that",
                                                               "there is no difference between A and B."))
    } else {
      sig_message <- div(class = "descriptions", "The test is", strong("NOT significant"), " at a 95% confidence level (p-value =",
                         format(round(p_val, 4), nsmall = 4, scientific = FALSE), 
                         ", which is greater than 0.05).", strong("We CANNOT reject the null hypothesis that",
                                                               "there is no difference between A and B."))
    }
    
    # We're using a one-tailed test if B > A and a two-tailed if B == A
    if(input$rate_a == input$rate_b){
      alternative <- "two-tailed"
    } else {
      alternative <- "one-tailed"
    }
    
    # Explanatory note
    exp_message <- div(class = "descriptions", 
                       em("The significance test run above was for a", alternative, "test with",  
                          "a confidence level of 95%. We're not going to get into",
                          "the minutia behind that here."))
    
    # Build up all three statements
    summary_message <- list(summary_message, sig_message, exp_message)
    
    summary_message
  }
})

# Recording if the type of result we've seen - true positive, false positive,...
output$result_type <- renderPlot({
  
  # Return nothing if no test has been run or if B < A
  if (input$run_test == 0 | input$rate_b < input$rate_a){
    return()
  } else {
    
    # Get the p-value
    p_val <- p_val()
    
    # Start with a case where the "truth" is that there IS a difference
    if(input$rate_a != input$rate_b){
      # Check for significance
      if(p_val < 0.05){
        result_text <- "True Positive"
        result_fill <- "green"
      } else {
        result_text <- "False Negative"
        result_fill <- "red"
      }
    } else {
      # A and B are the same in truth
      # Check for significance
      if(p_val < 0.05){
        result_text <- "False Positive"
        result_fill <- "red"
      } else {
        result_text <- "True Negative"
        result_fill <- "green"
      }
    }
    
    # Make a data frame for a simple plot
    gg_data <- data.frame(x = 1, y = 1, result = result_text)
    
    # Make the plot
    gg <- ggplot(data = gg_data,
                 mapping = aes(x = x, y = y, label = result)) +
      geom_text(size = 7, family = "Nunito") +
      theme_light() +
      theme(panel.background = element_rect(fill = result_fill),
            line = element_blank(),
            axis.text = element_blank(),
            axis.title = element_blank())
    gg
  }
})

# Visualize the actual vs. observed conversion rate lift
output$conv_rate_lift <- renderPlot({
  
  # Return nothing if no test has been run or if B < A
  if (input$run_test == 0 | input$rate_b < input$rate_a){
    return()
  } else {
    
    # Make the actual lift label
    label_actual <- paste0("Actual Lift:\n",
                           percent(rate_b_percent() - rate_a_percent()))
    label_observed <- paste0("Observed Lift:\n",
                             percent(b_observed() - a_observed()),
                             " +/- ",
                             percent((max_lift_proportion() - min_lift_proportion())/2))
    
    # Build the data frame with the values we need to make the bar 
    # chart with error bars
    conv_rate_lift_df <- data.frame(x = c(label_actual, label_observed),
                                    y = c(rate_b_percent() - rate_a_percent(),
                                          b_observed() - a_observed()),
                                    ymin = c(NA, min_lift_proportion()),
                                    ymax = c(NA, max_lift_proportion()))
    
    # Build the plot
    gg <- ggplot(data = conv_rate_lift_df, 
                 mapping = aes(x = x, y = y, fill = x, ymin = ymin, ymax = ymax)) +
      geom_bar(stat = "identity") +
      geom_errorbar(width = .06, color = "gray30") +
      geom_hline(aes(yintercept = 0)) +
      scale_fill_manual(values = c("#999999", "#00A2B1")) +
      scale_y_continuous(expand = c(0,0)) +
      theme_light() + theme(axis.title = element_blank(),
                            axis.text.y = element_blank(),
                            axis.text.x = element_text(size = 16, face="bold", 
                                                       family = "Nunito",
                                                       margin = margin(0.3,0,0,0,"cm")),
                            panel.border = element_blank(),
                            panel.grid = element_blank(),
                            legend.position = "nono" )
    
    gg
  }
  
})

output$annual_rev_message <- renderUI({
  
  # Return nothing if no test has been run or if B < A
  if (input$run_test == 0 | input$rate_b < input$rate_a){
    return()
  } else {
    
    # If the statistical significance wasn't achieved, then assume would not calculate
    # revenue lift at all.
    if (p_val() >= 0.05){
      
      rev_lift_full_message <- div(class = "descriptions", 
                                   "In this case, since we didn't achieve statistical significance with the",
                                   "test, no annualized revenue lift would have been calculated.")
      
    } else {
      
      # Put the base message
      base_message <- div(class = "descriptions",
                          "We can use the traffic volume, test duration, and average order value, along", 
                          "with our conversion rate lift calculations to see what annualized revenue looks like.", 
                          em("Keep in mind that these only work if we hold every other revenue factor constant",
                             "(and we still have a range even with that!)"), "The calculations below are calculated",
                          "using the", a(href = "https://www.kean.edu/~fosborne/bstat/06d2pop.html",
                                         "confidence interval for the difference of two population proportions."))
      
      
      # Calculate the actual annualized revenue lift. The "2*" is because the # of
      # visit(or)s in the simulation are for A and for B -- representing 1/2 of
      # the total volume.
      rev_lift_actual <- 2 * (rate_b_percent() - rate_a_percent()) * 
        input$num_observations / input$test_duration * 365 * input$aov
      
      # Calculate OBESRVED annualized revenue lift
      rev_lift_observed <- 2 * (b_observed() - a_observed()) * 
        input$num_observations / input$test_duration * 365 * input$aov
      
      # Calculate the minimum proportional lift (e.g., if the observed A and B had a 5% lift,
      # this would calculate the +/- from that lift to get a 95% confidence interval for the
      # true lift)
      min_lift_proportion <- min_lift_proportion()
      max_lift_proportion <- max_lift_proportion()
      
      # Calculate the min and max lifts
      min_lift <- 2 * min_lift_proportion * input$num_observations / input$test_duration * 365 * input$aov
      max_lift <- 2 * max_lift_proportion * input$num_observations / input$test_duration * 365 * input$aov
      
      # Build the message for the actual annualized revenue
      rev_message_actual <- div(class = "descriptions", 
                                "The ACTUAL annual revenue lift from running", em("B"), "instead of", em("A"), 
                                "would be:", strong(paste0("$", format(round(rev_lift_actual, 0), big.mark = ",", 
                                                                       nsmall = 0))),".")
      
      # Compose a message that compares the actual to the observed
      if(rev_lift_actual > rev_lift_observed){
        compare_message <- span("This would be an", strong("understatement"), "of the annualized revenue",
                                "impact by", strong(paste0("$", format(round(rev_lift_actual - rev_lift_observed,0), 
                                                                       big.mark = ",", nsmall = 0))), ".")
      } else {
        if(rev_lift_actual < rev_lift_observed){
          compare_message <- span("This would be an", strong("overstatement"), "of the annualized revenue",
                                  "impact by", strong(paste0("$", format(rev_lift_observed - rev_lift_actual, 
                                                                         big.mark = ",", nsmall = 0))), ".")
        } else {
          compare_message <- ""
        }
      }
      
      # Build the message for the annualized revenue based on the observed result
      rev_message_observed <- div(class = "descriptions", 
                                  "The annualized revenue lift based on the", 
                                  strong("observed result"), "from running", em("B"), 
                                  "instead of", em("A"), "would be:", 
                                  strong(paste0("$", format(round(rev_lift_observed, 0), big.mark = ",", nsmall = 0))),
                                  ".", compare_message)
      
      # Build a message based on whether the actual annualized revenue would fall within
      # the range of revenue based on the lift confidence interval
      if(rev_lift_actual >= min_lift & rev_lift_actual <= max_lift){
        range_result_message <- span("The actual annualized revenue", strong("would"), "fall within this range.")
      } else {
        range_result_message <- span("The actual annualized revenue", strong("would NOT"), "fall within this range.")
      }
      
      # Build the message that uses the lift confidence interval to calculate a range
      # annualized revenue.
      range_message <- div(class = "descriptions", 
                           "The expected annual revenue lift", strong("RANGE"), "(a 95% confidence interval)",
                           "from running", em("B"), 
                           "instead of", em("A"), "would be ", 
                           strong(paste0("$", format(round(min_lift,0), big.mark = ",", nsmall = 0), " to $",
                                         format(round(max_lift,0), big.mark = ",", nsmall = 0))),
                           ".", range_result_message)
      
      # Gather the messages together
      rev_lift_full_message <- list(base_message, rev_message_actual, rev_message_observed, range_message)
    }
  }
  rev_lift_full_message
})

```



